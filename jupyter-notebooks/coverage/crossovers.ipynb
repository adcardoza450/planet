{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossovers\n",
    "\n",
    "You've defined an AOI, you've specified the image types you are interested and the search query. Great! But are there crossovers between the image types? e.g. how many PSOrthotiles were collected within 1 day of a Landsat 8 scene?\n",
    "\n",
    "In this notebook, we will find that answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notebook dependencies\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "# import copy\n",
    "# from functools import partial\n",
    "import json\n",
    "import os\n",
    "\n",
    "import ipyleaflet as ipyl\n",
    "import ipywidgets as ipyw\n",
    "from IPython.display import display\n",
    "# import matplotlib\n",
    "# from matplotlib import cm\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "from planet import api\n",
    "from planet.api import filters\n",
    "# import pyproj\n",
    "# import rasterio\n",
    "# from rasterio import features as rfeatures\n",
    "# from shapely import geometry as sgeom\n",
    "# import shapely.ops\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AOI\n",
    "\n",
    "Define the AOI as a geojson polygon. This can be done at [geojson.io](http://geojson.io). If you use geojson.io, only copy the single aoi feature, not the entire feature collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aoi = {u'geometry': {u'type': u'Polygon', u'coordinates': [[[-121.3113248348236, 38.28911976564886], [-121.3113248348236, 38.34622533958], [-121.2344205379486, 38.34622533958], [-121.2344205379486, 38.28911976564886], [-121.3113248348236, 38.28911976564886]]]}, u'type': u'Feature', u'properties': {u'style': {u'opacity': 0.5, u'fillOpacity': 0.2, u'noClip': False, u'weight': 4, u'color': u'blue', u'lineCap': None, u'dashArray': None, u'smoothFactor': 1, u'stroke': True, u'fillColor': None, u'clickable': True, u'lineJoin': None, u'fill': True}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[-121.3113248348236, 38.28911976564886], [-121.3113248348236, 38.34622533958], [-121.2344205379486, 38.34622533958], [-121.2344205379486, 38.28911976564886], [-121.3113248348236, 38.28911976564886]]]}, \"type\": \"Feature\", \"properties\": {\"style\": {\"opacity\": 0.5, \"noClip\": false, \"weight\": 4, \"color\": \"blue\", \"lineCap\": null, \"smoothFactor\": 1, \"stroke\": true, \"fillOpacity\": 0.2, \"clickable\": true, \"fill\": true, \"dashArray\": null, \"fillColor\": null, \"lineJoin\": null}}}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(aoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Request\n",
    "\n",
    "Build the Planet API Filter request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filter': {'type': 'AndFilter', 'config': ({'config': {u'type': u'Polygon', u'coordinates': [[[-121.3113248348236, 38.28911976564886], [-121.3113248348236, 38.34622533958], [-121.2344205379486, 38.34622533958], [-121.2344205379486, 38.28911976564886], [-121.3113248348236, 38.28911976564886]]]}, 'field_name': 'geometry', 'type': 'GeometryFilter'}, {'config': {'lt': 5}, 'field_name': 'cloud_cover', 'type': 'RangeFilter'}, {'config': {'gt': 0}, 'field_name': 'sun_elevation', 'type': 'RangeFilter'}, {'config': {'gt': '2017-01-01T00:00:00Z'}, 'field_name': 'acquired', 'type': 'DateRangeFilter'}, {'config': {'lt': '2017-08-23T00:00:00Z'}, 'field_name': 'acquired', 'type': 'DateRangeFilter'})}, 'item_types': ['Landsat8L1G']}\n",
      "{'filter': {'type': 'AndFilter', 'config': ({'config': {u'type': u'Polygon', u'coordinates': [[[-121.3113248348236, 38.28911976564886], [-121.3113248348236, 38.34622533958], [-121.2344205379486, 38.34622533958], [-121.2344205379486, 38.28911976564886], [-121.3113248348236, 38.28911976564886]]]}, 'field_name': 'geometry', 'type': 'GeometryFilter'}, {'config': {'lt': 5}, 'field_name': 'cloud_cover', 'type': 'RangeFilter'}, {'config': {'gt': '2017-01-01T00:00:00Z'}, 'field_name': 'acquired', 'type': 'DateRangeFilter'}, {'config': {'lt': '2017-08-23T00:00:00Z'}, 'field_name': 'acquired', 'type': 'DateRangeFilter'})}, 'item_types': ['PSOrthoTile']}\n"
     ]
    }
   ],
   "source": [
    "# filters.build_search_request() item types:\n",
    "# Landsat 8 - 'Landsat8L1G'\n",
    "# Sentinel - 'Sentinel2L1C'\n",
    "# PS Orthotile = 'PSOrthoTile'\n",
    "\n",
    "def build_landsat_request(aoi_geom, start_date, stop_date):\n",
    "    # need to add filter for quality_category to only get L1T day scenes\n",
    "    # with all the assets\n",
    "    query = filters.and_filter(\n",
    "        filters.geom_filter(aoi_geom),\n",
    "        filters.range_filter('cloud_cover', lt=5),\n",
    "        # ensure has all assets, unfortunately also filters 'L1TP'\n",
    "#         filters.string_filter('quality_category', 'standard'), \n",
    "        filters.range_filter('sun_elevation', gt=0), # filter out night scenes\n",
    "        filters.date_range('acquired', gt=start_date),\n",
    "        filters.date_range('acquired', lt=stop_date)\n",
    "    )\n",
    "\n",
    "    return filters.build_search_request(query, ['Landsat8L1G'])    \n",
    "    \n",
    "    \n",
    "def build_ps_request(aoi_geom, start_date, stop_date):\n",
    "    query = filters.and_filter(\n",
    "        filters.geom_filter(aoi_geom),\n",
    "        filters.range_filter('cloud_cover', lt=5),\n",
    "        filters.date_range('acquired', gt=start_date),\n",
    "        filters.date_range('acquired', lt=stop_date)\n",
    "    )\n",
    "\n",
    "    return filters.build_search_request(query, ['PSOrthoTile'])\n",
    "\n",
    "\n",
    "start_date = datetime.datetime(year=2017,month=1,day=1)\n",
    "stop_date = datetime.datetime(year=2017,month=8,day=23)\n",
    "\n",
    "print(build_landsat_request(aoi['geometry'], start_date, stop_date))\n",
    "print(build_ps_request(aoi['geometry'], start_date, stop_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Planet API\n",
    "\n",
    "The client is how we interact with the planet api. It is created with the user-specific api key, which is pulled from $PL_API_KEY environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_api_key():\n",
    "    return os.environ['PL_API_KEY']\n",
    "\n",
    "# quick check that key is defined\n",
    "assert get_api_key(), \"PL_API_KEY not defined.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "def create_client():\n",
    "    return api.ClientV1(api_key=get_api_key())\n",
    "\n",
    "def search_pl_api(request, limit=500):\n",
    "    client = create_client()\n",
    "    result = client.quick_search(request)\n",
    "    \n",
    "    # note that this returns a generator\n",
    "    return result.items_iter(limit=limit)\n",
    "\n",
    "\n",
    "items = list(search_pl_api(build_ps_request(aoi['geometry'], start_date, stop_date)))\n",
    "print(len(items))\n",
    "# uncomment below to see entire metadata for a PS orthotile\n",
    "# print(json.dumps(items[0], indent=4))\n",
    "del items\n",
    "\n",
    "items = list(search_pl_api(build_landsat_request(aoi['geometry'], start_date, stop_date)))\n",
    "print(len(items))\n",
    "# uncomment below to see entire metadata for a landsat scene\n",
    "# print(json.dumps(items[0], indent=4))\n",
    "del items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In processing the items to scenes, we are only using a small subset of the [product metadata](https://www.planet.com/docs/spec-sheets/sat-imagery/#product-metadata). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anomalous_pixels</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>collection</th>\n",
       "      <th>columns</th>\n",
       "      <th>data_type</th>\n",
       "      <th>epsg_code</th>\n",
       "      <th>footprint</th>\n",
       "      <th>gsd</th>\n",
       "      <th>id</th>\n",
       "      <th>instrument</th>\n",
       "      <th>...</th>\n",
       "      <th>rows</th>\n",
       "      <th>satellite_id</th>\n",
       "      <th>sun_azimuth</th>\n",
       "      <th>sun_elevation</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>updated</th>\n",
       "      <th>usable_data</th>\n",
       "      <th>view_angle</th>\n",
       "      <th>wrs_path</th>\n",
       "      <th>wrs_row</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acquired</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-05 18:45:52.748510</th>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7671</td>\n",
       "      <td>L1T</td>\n",
       "      <td>32610</td>\n",
       "      <td>{u'type': u'Polygon', u'coordinates': [[[-122....</td>\n",
       "      <td>30</td>\n",
       "      <td>LC80440332017005LGN00</td>\n",
       "      <td>OLI_TIRS</td>\n",
       "      <td>...</td>\n",
       "      <td>7801</td>\n",
       "      <td>Landsat8</td>\n",
       "      <td>157.9</td>\n",
       "      <td>25.3</td>\n",
       "      <td>https://api.planet.com/data/v1/item-types/Land...</td>\n",
       "      <td>2017-04-26T14:09:25Z</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            anomalous_pixels  cloud_cover collection  columns  \\\n",
       "acquired                                                                        \n",
       "2017-01-05 18:45:52.748510                 0         0.15        NaN     7671   \n",
       "\n",
       "                           data_type  epsg_code  \\\n",
       "acquired                                          \n",
       "2017-01-05 18:45:52.748510       L1T      32610   \n",
       "\n",
       "                                                                    footprint  \\\n",
       "acquired                                                                        \n",
       "2017-01-05 18:45:52.748510  {u'type': u'Polygon', u'coordinates': [[[-122....   \n",
       "\n",
       "                            gsd                     id instrument   ...     \\\n",
       "acquired                                                            ...      \n",
       "2017-01-05 18:45:52.748510   30  LC80440332017005LGN00   OLI_TIRS   ...      \n",
       "\n",
       "                            rows  satellite_id  sun_azimuth  sun_elevation  \\\n",
       "acquired                                                                     \n",
       "2017-01-05 18:45:52.748510  7801      Landsat8        157.9           25.3   \n",
       "\n",
       "                                                                    thumbnail  \\\n",
       "acquired                                                                        \n",
       "2017-01-05 18:45:52.748510  https://api.planet.com/data/v1/item-types/Land...   \n",
       "\n",
       "                                         updated usable_data view_angle  \\\n",
       "acquired                                                                  \n",
       "2017-01-05 18:45:52.748510  2017-04-26T14:09:25Z        0.68          0   \n",
       "\n",
       "                           wrs_path  wrs_row  \n",
       "acquired                                      \n",
       "2017-01-05 18:45:52.748510       44       33  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def items_to_scenes(items):\n",
    "    item_types = []\n",
    "\n",
    "    def _get_props(item):\n",
    "        props = item['properties']\n",
    "        props.update({\n",
    "            'thumbnail': item['_links']['thumbnail'],\n",
    "            'item_type': item['properties']['item_type'],\n",
    "            'id': item['id'],\n",
    "            'acquired': item['properties']['acquired'],\n",
    "            'footprint': item['geometry']\n",
    "        })\n",
    "        return props\n",
    "    \n",
    "    scenes = pd.DataFrame(data=[_get_props(i) for i in items])\n",
    "    \n",
    "    # acquired column to index, for faster processing\n",
    "    scenes.index = pd.to_datetime(scenes['acquired'])\n",
    "    del scenes['acquired']\n",
    "    scenes.sort_index(inplace=True)\n",
    "    \n",
    "    return scenes\n",
    "\n",
    "scenes = items_to_scenes(search_pl_api(build_landsat_request(aoi['geometry'], start_date, stop_date)))\n",
    "display(scenes[:1])\n",
    "del scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate Landsat Scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "landsat_scenes = items_to_scenes(search_pl_api(build_landsat_request(aoi['geometry'], start_date, stop_date)))\n",
    "print(len(landsat_scenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landsat_scenes_to_features_layer(scenes):\n",
    "    features_style = {\n",
    "            'color': 'grey',\n",
    "            'weight': 1,\n",
    "            'fillColor': 'grey',\n",
    "            'fillOpacity': 0.15}\n",
    "\n",
    "    features = [{\"geometry\": r.footprint,\n",
    "                 \"type\": \"Feature\",\n",
    "                 \"properties\": {\"style\": features_style,\n",
    "                                \"wrs_path\": r.wrs_path,\n",
    "                                \"wrs_row\": r.wrs_row}}\n",
    "                for r in scenes.itertuples()]\n",
    "    return features\n",
    "\n",
    "def create_landsat_hover_handler(scenes):\n",
    "    def hover_handler(event=None, id=None, properties=None):\n",
    "        wrs_path = properties['wrs_path']\n",
    "        wrs_row = properties['wrs_row']\n",
    "        path_row_query = 'wrs_path=={} and wrs_row=={}'.format(wrs_path, wrs_row)\n",
    "        count = len(scenes.query(path_row_query))\n",
    "        label.value = 'path: {}, row: {}, count: {}'.format(wrs_path, wrs_row, count)\n",
    "    return hover_handler\n",
    "\n",
    "\n",
    "def create_landsat_feature_layer(scenes):\n",
    "    \n",
    "    features = landsat_scenes_to_features_layer(scenes)\n",
    "    \n",
    "    # Footprint feature layer\n",
    "    feature_collection = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }\n",
    "\n",
    "    feature_layer = ipyl.GeoJSON(data=feature_collection)\n",
    "\n",
    "    label = ipyw.Label(layout=ipyw.Layout(width='100%'))\n",
    "\n",
    "    feature_layer.on_hover(create_landsat_hover_handler(scenes))\n",
    "    return feature_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize map using parameters from above map\n",
    "# and deleting map instance if it exists\n",
    "try:\n",
    "    del fp_map\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "\n",
    "zoom = 6\n",
    "center = [38.28993659801203, -120.14648437499999] # lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d895349ecf9f41438921039fabd6b4c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create map, adding box drawing controls\n",
    "# Reuse parameters if map already exists\n",
    "try:\n",
    "    center = fp_map.center\n",
    "    zoom = fp_map.zoom\n",
    "    print(zoom)\n",
    "    print(center)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Change tile layer to one that makes it easier to see crop features\n",
    "# Layer selected using https://leaflet-extras.github.io/leaflet-providers/preview/\n",
    "map_tiles = ipyl.TileLayer(url='http://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}.png')\n",
    "fp_map = ipyl.Map(\n",
    "        center=center, \n",
    "        zoom=zoom,\n",
    "        default_tiles = map_tiles\n",
    "    )\n",
    "\n",
    "fp_map.add_layer(create_landsat_feature_layer(landsat_scenes)) # landsat layer\n",
    "fp_map.add_layer(ipyl.GeoJSON(data=aoi)) # aoi layer\n",
    "    \n",
    "# Display map and label\n",
    "ipyw.VBox([fp_map, label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This AOI is located in a region covered by 3 different path/row tiles. This means there is 3x the coverage than in regions only covered by one path/row tile. This is particularly lucky!\n",
    "\n",
    "What about the within each path/row tile. How long and how consistent is the Landsat 8 collect period for each path/row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrs_path</th>\n",
       "      <th>wrs_row</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">43</th>\n",
       "      <th>33</th>\n",
       "      <td>12</td>\n",
       "      <td>31 days 23:59:46.812643</td>\n",
       "      <td>17 days 07:59:59.313376</td>\n",
       "      <td>16 days 00:00:04.366736</td>\n",
       "      <td>15 days 23:59:50.258638</td>\n",
       "      <td>4 days 14:51:00.569425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>13</td>\n",
       "      <td>16 days 00:00:11.536172</td>\n",
       "      <td>15 days 23:59:59.366519</td>\n",
       "      <td>15 days 23:59:55.543541</td>\n",
       "      <td>15 days 23:59:50.262876</td>\n",
       "      <td>0 days 00:00:07.696147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <th>33</th>\n",
       "      <td>14</td>\n",
       "      <td>16 days 00:00:10.236295</td>\n",
       "      <td>15 days 23:59:59.404161</td>\n",
       "      <td>15 days 23:59:59.511409</td>\n",
       "      <td>15 days 23:59:49.212960</td>\n",
       "      <td>0 days 00:00:07.579903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count                      max                     mean  \\\n",
       "wrs_path wrs_row                                                            \n",
       "43       33          12  31 days 23:59:46.812643  17 days 07:59:59.313376   \n",
       "         34          13  16 days 00:00:11.536172  15 days 23:59:59.366519   \n",
       "44       33          14  16 days 00:00:10.236295  15 days 23:59:59.404161   \n",
       "\n",
       "                                   median                      min  \\\n",
       "wrs_path wrs_row                                                     \n",
       "43       33       16 days 00:00:04.366736  15 days 23:59:50.258638   \n",
       "         34       15 days 23:59:55.543541  15 days 23:59:50.262876   \n",
       "44       33       15 days 23:59:59.511409  15 days 23:59:49.212960   \n",
       "\n",
       "                                     std  \n",
       "wrs_path wrs_row                          \n",
       "43       33       4 days 14:51:00.569425  \n",
       "         34       0 days 00:00:07.696147  \n",
       "44       33       0 days 00:00:07.579903  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def time_diff_stats(group):\n",
    "    time_diff = group.index.to_series().diff() # time difference between rows in group\n",
    "    stats = {'median': time_diff.median(),\n",
    "             'mean': time_diff.mean(),\n",
    "             'std': time_diff.std(),\n",
    "             'count': time_diff.count(),\n",
    "             'min': time_diff.min(),\n",
    "             'max': time_diff.max()}\n",
    "    return pd.Series(stats)\n",
    "\n",
    "landsat_scenes.groupby(['wrs_path', 'wrs_row']).apply(time_diff_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the collection period is just 10seconds short of 16 days. \n",
    "\n",
    "path/row 43/33 is missing one image which causes an unusually long collect period.\n",
    "\n",
    "What this means is that we don't need to look at every Landsat 8 scene collect time to find crossovers with Planet scenes. We could look at the first scene for each path/row, then look at every 16 day increment. However, we will need to account for dropped Landsat 8 scenes in some way.\n",
    "\n",
    "What is the time difference between the tiles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wrs_path  wrs_row\n",
       "43        33        2017-03-03 18:39:20.127296\n",
       "          34        2017-03-03 18:39:44.009861\n",
       "44        33        2017-03-10 18:45:27.068563\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_closest(date_time, data_frame):\n",
    "    time_deltas = (data_frame.index - date_time).to_series().reset_index(drop=True).abs()\n",
    "    idx_min = time_deltas.idxmin()\n",
    "\n",
    "    min_delta = time_deltas[idx_min]\n",
    "    return (idx_min, min_delta)\n",
    "\n",
    "def closest_time(group):\n",
    "    inquiry_date = datetime.datetime(year=2017,month=3,day=7)\n",
    "    idx, _ = find_closest(inquiry_date, group)\n",
    "    return group.index.to_series().iloc[idx]\n",
    "\n",
    "\n",
    "landsat_scenes.groupby(['wrs_path', 'wrs_row']).apply(closest_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the tiles that are in the same path are very close (20sec) together, basically from the same day. Therefore, we would want to only use one tile and pick the best image.\n",
    "\n",
    "Tiles that are in different paths are 7 days apart. Therefore, we want to keep tiles from different paths, as they represent unique crossovers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate PS Scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anomalous_pixels</th>\n",
       "      <th>black_fill</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>columns</th>\n",
       "      <th>epsg_code</th>\n",
       "      <th>footprint</th>\n",
       "      <th>grid_cell</th>\n",
       "      <th>ground_control</th>\n",
       "      <th>gsd</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>published</th>\n",
       "      <th>rows</th>\n",
       "      <th>satellite_id</th>\n",
       "      <th>strip_id</th>\n",
       "      <th>sun_azimuth</th>\n",
       "      <th>sun_elevation</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>updated</th>\n",
       "      <th>usable_data</th>\n",
       "      <th>view_angle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acquired</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-21 18:06:20.982805</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.743849</td>\n",
       "      <td>0.239</td>\n",
       "      <td>8000</td>\n",
       "      <td>32610</td>\n",
       "      <td>{u'type': u'Polygon', u'coordinates': [[[-121....</td>\n",
       "      <td>1056721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.967036</td>\n",
       "      <td>371816_1056721_2017-01-21_0e30</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-01-22T05:48:31Z</td>\n",
       "      <td>8000</td>\n",
       "      <td>0e30</td>\n",
       "      <td>371816</td>\n",
       "      <td>146.1</td>\n",
       "      <td>24.4</td>\n",
       "      <td>https://api.planet.com/data/v1/item-types/PSOr...</td>\n",
       "      <td>2017-01-30T12:17:20Z</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            anomalous_pixels  black_fill  cloud_cover  \\\n",
       "acquired                                                                \n",
       "2017-01-21 18:06:20.982805              0.24    0.743849        0.239   \n",
       "\n",
       "                            columns  epsg_code  \\\n",
       "acquired                                         \n",
       "2017-01-21 18:06:20.982805     8000      32610   \n",
       "\n",
       "                                                                    footprint  \\\n",
       "acquired                                                                        \n",
       "2017-01-21 18:06:20.982805  {u'type': u'Polygon', u'coordinates': [[[-121....   \n",
       "\n",
       "                           grid_cell ground_control       gsd  \\\n",
       "acquired                                                        \n",
       "2017-01-21 18:06:20.982805   1056721            NaN  3.967036   \n",
       "\n",
       "                                                        id     ...      \\\n",
       "acquired                                                       ...       \n",
       "2017-01-21 18:06:20.982805  371816_1056721_2017-01-21_0e30     ...       \n",
       "\n",
       "                                       published  rows  satellite_id  \\\n",
       "acquired                                                               \n",
       "2017-01-21 18:06:20.982805  2017-01-22T05:48:31Z  8000          0e30   \n",
       "\n",
       "                            strip_id sun_azimuth sun_elevation  \\\n",
       "acquired                                                         \n",
       "2017-01-21 18:06:20.982805    371816       146.1          24.4   \n",
       "\n",
       "                                                                    thumbnail  \\\n",
       "acquired                                                                        \n",
       "2017-01-21 18:06:20.982805  https://api.planet.com/data/v1/item-types/PSOr...   \n",
       "\n",
       "                                         updated usable_data  view_angle  \n",
       "acquired                                                                  \n",
       "2017-01-21 18:06:20.982805  2017-01-30T12:17:20Z        0.02         0.1  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps_scenes = items_to_scenes(search_pl_api(build_ps_request(aoi['geometry'], start_date, stop_date)))\n",
    "print(len(ps_scenes))\n",
    "display(ps_scenes[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, PS scenes have daily coverage over all regions. We want to identify images that occur on the same day and only select the best ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_ps_scenes = ps_scenes.index.to_series().groupby([ps_scenes.index.year,\n",
    "                                                       ps_scenes.index.month,\n",
    "                                                       ps_scenes.index.day])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017  4  20    2\n",
       "         29    2\n",
       "      5  7     2\n",
       "         18    2\n",
       "         21    2\n",
       "      6  14    2\n",
       "         16    2\n",
       "         17    3\n",
       "         22    3\n",
       "         27    3\n",
       "      7  1     2\n",
       "         2     3\n",
       "         4     3\n",
       "         6     2\n",
       "         7     2\n",
       "         8     2\n",
       "         10    2\n",
       "         11    2\n",
       "         13    3\n",
       "         17    2\n",
       "         20    3\n",
       "         21    2\n",
       "         26    2\n",
       "         27    2\n",
       "         28    2\n",
       "         29    2\n",
       "         31    2\n",
       "      8  2     2\n",
       "         7     3\n",
       "         8     2\n",
       "         15    3\n",
       "         21    2\n",
       "Name: acquired, dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_count = daily_ps_scenes.agg('count')\n",
    "daily_count[daily_count > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>scenes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2017</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">20</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-20 18:01:32.425201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-20 18:09:59.004133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">29</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-29 18:01:16.191189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-29 18:02:17.982774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count                     scenes\n",
       "2017 4 20 0      2 2017-04-20 18:01:32.425201\n",
       "          1      2 2017-04-20 18:09:59.004133\n",
       "       29 0      2 2017-04-29 18:01:16.191189\n",
       "          1      2 2017-04-29 18:02:17.982774"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scenes_and_count(group):\n",
    "    entry = {'count': len(group),\n",
    "             'scenes': group.index.tolist()}\n",
    "    \n",
    "    return pd.DataFrame(entry)\n",
    "\n",
    "daily_count_and_scenes = daily_ps_scenes.apply(scenes_and_count)\n",
    "multiplecoverage = daily_count_and_scenes.query('ilevel_1 == 4 and count > 1')\n",
    "multiplecoverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Crossovers\n",
    "\n",
    "Use pandas magic to break scenes up by types (`item_type`), then find matching days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/36933725/pandas-time-series-join-by-closest-time\n",
    "def find_closest(aquired_time, data_frame):\n",
    "    time_deltas = (data_frame.index - aquired_time).to_series().reset_index(drop=True).abs()\n",
    "    idx_min = time_deltas.idxmin()\n",
    "\n",
    "    min_delta = time_deltas[idx_min]\n",
    "    return (idx_min, min_delta)\n",
    "\n",
    "\n",
    "def find_crossovers(aquired_time):\n",
    "    closest_idx, closest_delta = find_closest(aquired_time, landsat_scenes)\n",
    "    closest_landsat = landsat_scenes.iloc[idx_min]\n",
    "\n",
    "    crossover = {'landsat_acquisition': closest_landsat.name,\n",
    "                 'delta': min_delta}\n",
    "    return pd.Series(crossover)\n",
    "\n",
    "ps_scenes = items_to_scenes(search_pl_api(build_ps_request(aoi['geometry'], start_date, stop_date)))\n",
    "\n",
    "# apply closest_landsat_info() to each row\n",
    "crossovers = ps_scenes.index.to_series().apply(find_closest)\n",
    "crossovers[crossovers['delta'] < pd.Timedelta('1 days')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta</th>\n",
       "      <th>landsat_acquisition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acquired</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-21 18:06:20.982805</th>\n",
       "      <td>00:39:27.144472</td>\n",
       "      <td>2017-01-21 18:45:48.127277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-30 18:07:08.365512</th>\n",
       "      <td>00:32:24.949141</td>\n",
       "      <td>2017-01-30 18:39:33.314653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-20 18:01:32.425201</th>\n",
       "      <td>00:37:21.460219</td>\n",
       "      <td>2017-04-20 18:38:53.885420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-20 18:09:59.004133</th>\n",
       "      <td>00:28:54.881287</td>\n",
       "      <td>2017-04-20 18:38:53.885420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-27 18:03:00.275770</th>\n",
       "      <td>00:41:59.185523</td>\n",
       "      <td>2017-04-27 18:44:59.461293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-06 18:08:35.673239</th>\n",
       "      <td>00:30:13.751485</td>\n",
       "      <td>2017-05-06 18:38:49.424724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-07 18:02:14.522227</th>\n",
       "      <td>23:23:01.206464</td>\n",
       "      <td>2017-05-06 18:39:13.315763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-07 18:02:49.753154</th>\n",
       "      <td>23:23:36.437391</td>\n",
       "      <td>2017-05-06 18:39:13.315763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-13 18:02:27.453337</th>\n",
       "      <td>00:42:38.184447</td>\n",
       "      <td>2017-05-13 18:45:05.637784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-23 18:03:06.953463</th>\n",
       "      <td>23:23:42.101528</td>\n",
       "      <td>2017-05-22 18:39:24.851935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-30 18:03:01.482275</th>\n",
       "      <td>23:17:45.608196</td>\n",
       "      <td>2017-05-29 18:45:15.874079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-07 18:09:52.583459</th>\n",
       "      <td>00:29:16.785794</td>\n",
       "      <td>2017-06-07 18:39:09.369253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-14 18:04:11.127509</th>\n",
       "      <td>00:41:11.858711</td>\n",
       "      <td>2017-06-14 18:45:22.986220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-14 18:04:11.900359</th>\n",
       "      <td>00:41:11.085861</td>\n",
       "      <td>2017-06-14 18:45:22.986220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-23 18:04:26.540231</th>\n",
       "      <td>00:34:48.463894</td>\n",
       "      <td>2017-06-23 18:39:15.004125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-24 18:04:17.588324</th>\n",
       "      <td>23:24:38.693162</td>\n",
       "      <td>2017-06-23 18:39:38.895162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30 18:04:29.381121</th>\n",
       "      <td>00:40:58.068019</td>\n",
       "      <td>2017-06-30 18:45:27.449140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-01 18:03:25.712115</th>\n",
       "      <td>23:17:58.262975</td>\n",
       "      <td>2017-06-30 18:45:27.449140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-01 18:05:55.642145</th>\n",
       "      <td>23:20:28.193005</td>\n",
       "      <td>2017-06-30 18:45:27.449140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-09 18:06:27.610673</th>\n",
       "      <td>00:32:50.492053</td>\n",
       "      <td>2017-07-09 18:39:18.102726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-10 18:04:23.820878</th>\n",
       "      <td>23:24:41.835584</td>\n",
       "      <td>2017-07-09 18:39:41.985294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-10 18:05:36.065335</th>\n",
       "      <td>23:25:54.080041</td>\n",
       "      <td>2017-07-09 18:39:41.985294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-16 18:06:32.927964</th>\n",
       "      <td>00:38:58.165228</td>\n",
       "      <td>2017-07-16 18:45:31.093192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-17 18:05:41.353902</th>\n",
       "      <td>23:20:10.260710</td>\n",
       "      <td>2017-07-16 18:45:31.093192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-17 18:07:58.740699</th>\n",
       "      <td>23:22:27.647507</td>\n",
       "      <td>2017-07-16 18:45:31.093192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-25 18:06:03.712244</th>\n",
       "      <td>00:33:21.266516</td>\n",
       "      <td>2017-07-25 18:39:24.978760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-26 18:06:40.466169</th>\n",
       "      <td>23:26:51.600606</td>\n",
       "      <td>2017-07-25 18:39:48.865563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-26 18:09:11.648432</th>\n",
       "      <td>23:29:22.782869</td>\n",
       "      <td>2017-07-25 18:39:48.865563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-02 18:05:20.009239</th>\n",
       "      <td>23:19:41.099553</td>\n",
       "      <td>2017-08-01 18:45:38.909686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-02 18:06:21.267737</th>\n",
       "      <td>23:20:42.358051</td>\n",
       "      <td>2017-08-01 18:45:38.909686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-10 18:07:08.680191</th>\n",
       "      <td>00:32:22.811327</td>\n",
       "      <td>2017-08-10 18:39:31.491518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     delta        landsat_acquisition\n",
       "acquired                                                             \n",
       "2017-01-21 18:06:20.982805 00:39:27.144472 2017-01-21 18:45:48.127277\n",
       "2017-01-30 18:07:08.365512 00:32:24.949141 2017-01-30 18:39:33.314653\n",
       "2017-04-20 18:01:32.425201 00:37:21.460219 2017-04-20 18:38:53.885420\n",
       "2017-04-20 18:09:59.004133 00:28:54.881287 2017-04-20 18:38:53.885420\n",
       "2017-04-27 18:03:00.275770 00:41:59.185523 2017-04-27 18:44:59.461293\n",
       "2017-05-06 18:08:35.673239 00:30:13.751485 2017-05-06 18:38:49.424724\n",
       "2017-05-07 18:02:14.522227 23:23:01.206464 2017-05-06 18:39:13.315763\n",
       "2017-05-07 18:02:49.753154 23:23:36.437391 2017-05-06 18:39:13.315763\n",
       "2017-05-13 18:02:27.453337 00:42:38.184447 2017-05-13 18:45:05.637784\n",
       "2017-05-23 18:03:06.953463 23:23:42.101528 2017-05-22 18:39:24.851935\n",
       "2017-05-30 18:03:01.482275 23:17:45.608196 2017-05-29 18:45:15.874079\n",
       "2017-06-07 18:09:52.583459 00:29:16.785794 2017-06-07 18:39:09.369253\n",
       "2017-06-14 18:04:11.127509 00:41:11.858711 2017-06-14 18:45:22.986220\n",
       "2017-06-14 18:04:11.900359 00:41:11.085861 2017-06-14 18:45:22.986220\n",
       "2017-06-23 18:04:26.540231 00:34:48.463894 2017-06-23 18:39:15.004125\n",
       "2017-06-24 18:04:17.588324 23:24:38.693162 2017-06-23 18:39:38.895162\n",
       "2017-06-30 18:04:29.381121 00:40:58.068019 2017-06-30 18:45:27.449140\n",
       "2017-07-01 18:03:25.712115 23:17:58.262975 2017-06-30 18:45:27.449140\n",
       "2017-07-01 18:05:55.642145 23:20:28.193005 2017-06-30 18:45:27.449140\n",
       "2017-07-09 18:06:27.610673 00:32:50.492053 2017-07-09 18:39:18.102726\n",
       "2017-07-10 18:04:23.820878 23:24:41.835584 2017-07-09 18:39:41.985294\n",
       "2017-07-10 18:05:36.065335 23:25:54.080041 2017-07-09 18:39:41.985294\n",
       "2017-07-16 18:06:32.927964 00:38:58.165228 2017-07-16 18:45:31.093192\n",
       "2017-07-17 18:05:41.353902 23:20:10.260710 2017-07-16 18:45:31.093192\n",
       "2017-07-17 18:07:58.740699 23:22:27.647507 2017-07-16 18:45:31.093192\n",
       "2017-07-25 18:06:03.712244 00:33:21.266516 2017-07-25 18:39:24.978760\n",
       "2017-07-26 18:06:40.466169 23:26:51.600606 2017-07-25 18:39:48.865563\n",
       "2017-07-26 18:09:11.648432 23:29:22.782869 2017-07-25 18:39:48.865563\n",
       "2017-08-02 18:05:20.009239 23:19:41.099553 2017-08-01 18:45:38.909686\n",
       "2017-08-02 18:06:21.267737 23:20:42.358051 2017-08-01 18:45:38.909686\n",
       "2017-08-10 18:07:08.680191 00:32:22.811327 2017-08-10 18:39:31.491518"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/36933725/pandas-time-series-join-by-closest-time\n",
    "def find_closest(ps_datetime):\n",
    "    time_deltas = (landsat_scenes.index - ps_datetime).to_series().reset_index(drop=True).abs()\n",
    "    idx_min = time_deltas.idxmin()\n",
    "\n",
    "    min_delta = time_deltas[idx_min]\n",
    "\n",
    "    closest_landsat = landsat_scenes.iloc[idx_min]\n",
    "\n",
    "    crossover = {'landsat_acquisition': closest_landsat.name,\n",
    "                 'delta': min_delta}\n",
    "    return pd.Series(crossover)\n",
    "\n",
    "ps_scenes = items_to_scenes(search_pl_api(build_ps_request(aoi['geometry'], start_date, stop_date)))\n",
    "\n",
    "# apply closest_landsat_info() to each row\n",
    "crossovers = ps_scenes.index.to_series().apply(find_closest)\n",
    "crossovers[crossovers['delta'] < pd.Timedelta('1 days')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
