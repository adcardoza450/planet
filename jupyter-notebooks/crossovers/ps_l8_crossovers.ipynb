{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS Orthotile and Landsat 8 Crossovers\n",
    "\n",
    "Have you ever wanted to compare PS images to Landsat 8 images? Both image collections are made available via the Planet API. However, it takes a bit of work to identify crossovers - that is, images of the same area that were collected within a reasonable time difference of each other. Also, you may be interested in filtering out some imagery, e.g. cloudy images.\n",
    "\n",
    "This notebook walks you through the process of finding crossovers between PS Orthotiles and Landsat 8 scenes. In this notebook, we specify 'crossovers' as images that have been taken within 1hr of eachother. This time gap is sufficiently small that we expect the atmospheric conditions won't change much (this assumption doesn't always hold, but is the best we can do for now). We also filter out cloudy images and constrain our search to images collected in 2017, January 1 through August 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook dependencies\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "import ipyleaflet as ipyl\n",
    "import ipywidgets as ipyw\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from planet import Auth\n",
    "from planet import Session, DataClient, OrdersClient\n",
    "from shapely import geometry as sgeom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your Planet API Key is not set as an environment variable, you can paste it below\n",
    "if os.environ.get('PL_API_KEY', ''):\n",
    "    API_KEY = os.environ.get('PL_API_KEY', '')\n",
    "else:\n",
    "    API_KEY = 'PASTE_YOUR_API_KEY_HERE'\n",
    "\n",
    "client = Auth.from_key(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AOI\n",
    "\n",
    "Define the AOI as a geojson polygon. This can be done at [geojson.io](http://geojson.io). If you use geojson.io, only copy the single aoi feature, not the entire feature collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = {u'type': u'Polygon', u'coordinates': [[[-121.3113248348236, 38.28911976564886], [-121.3113248348236, 38.34622533958], [-121.2344205379486, 38.34622533958], [-121.2344205379486, 38.28911976564886], [-121.3113248348236, 38.28911976564886]]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(aoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Request\n",
    "\n",
    "Build the Planet API Filter request for the Landsat 8 and PS Orthotile imagery taken in 2017 through August 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filters we'll use to find our data\n",
    "\n",
    "item_type_LS = ['Landsat8L1G']\n",
    "\n",
    "item_type_PSOT = ['PSOrthoTile']\n",
    "\n",
    "geom_filter = {\n",
    "   \"type\":\"GeometryFilter\",\n",
    "   \"field_name\":\"geometry\",\n",
    "   \"config\":aoi\n",
    "}\n",
    "\n",
    "sun_elevation_filter = {\n",
    "   \"type\":\"RangeFilter\",\n",
    "   \"field_name\":\"sun_elevation\",\n",
    "   \"config\":{\n",
    "       \"lt\": 0}\n",
    "}\n",
    "\n",
    "cloud_cover_filter = {\n",
    "\"type\":\"RangeFilter\",\n",
    "\"field_name\":\"cloud_cover\",\n",
    "\"config\":{\n",
    "  \"lt\":5 }\n",
    "}\n",
    "\n",
    "date_range_filter = {\n",
    "\"type\":\"DateRangeFilter\",\n",
    "\"field_name\":\"acquired\",\n",
    "\"config\":{\n",
    "  \"gt\":\"2017-01-01T00:00:00Z\", \n",
    "   \"lt\": \"2017-08-23T00:00:00Z\"}\n",
    "}\n",
    "\n",
    "combined_filter_LS = {\n",
    "\"type\":\"AndFilter\",\n",
    "\"config\":[\n",
    "    geom_filter,\n",
    "    date_range_filter,\n",
    "    cloud_cover_filter,\n",
    "    sun_elevation_filter]\n",
    "}\n",
    "\n",
    "combined_filter_PSOrtho = {\n",
    "\"type\":\"AndFilter\",\n",
    "\"config\":[\n",
    "    geom_filter,\n",
    "    date_range_filter,\n",
    "    cloud_cover_filter]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Planet API\n",
    "\n",
    "The client is how we interact with the planet api. It is created with the user-specific api key, which is pulled from $PL_API_KEY environment variable. Create the client then use it to search for PS Orthotile and Landsat 8 scenes. Save a subset of the metadata provided by Planet API as our 'scene'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a quick search for our LANDSAT data\n",
    "async with Session() as sess:\n",
    "    cl = DataClient(sess)\n",
    "    results = await cl.search(name='landsat_search',search_filter=combined_filter_LS, item_types=item_type_LS)\n",
    "    landsat_list = [i async for i in results]\n",
    "    \n",
    "print(len(landsat_list))\n",
    "    \n",
    "# Run a quick search for our PSOrthoTile data\n",
    "async with Session() as sess:\n",
    "    cl = DataClient(sess)\n",
    "    results = await cl.search(name='psortho_search',search_filter=combined_filter_PSOrtho, item_types=item_type_PSOT)\n",
    "    psortho_list = [i async for i in results]\n",
    "    \n",
    "print(len(psortho_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In processing the items to scenes, we are only using a small subset of the [product metadata](https://www.planet.com/docs/spec-sheets/sat-imagery/#product-metadata). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def items_to_scenes(items):\n",
    "    item_types = []\n",
    "\n",
    "    def _get_props(item):\n",
    "        props = item['properties']\n",
    "        props.update({\n",
    "            'thumbnail': item['_links']['thumbnail'],\n",
    "            'item_type': item['properties']['item_type'],\n",
    "            'id': item['id'],\n",
    "            'acquired': item['properties']['acquired'],\n",
    "            'footprint': item['geometry']\n",
    "        })\n",
    "        return props\n",
    "    \n",
    "    scenes = pd.DataFrame(data=[_get_props(i) for i in items])\n",
    "    \n",
    "    # acquired column to index, it is unique and will be used a lot for processing\n",
    "    scenes.index = pd.to_datetime(scenes['acquired'])\n",
    "    del scenes['acquired']\n",
    "    scenes.sort_index(inplace=True)\n",
    "    \n",
    "    return scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate Landsat Scenes\n",
    "\n",
    "There are quite a few Landsat 8 scenes that are returned by our query. What do the footprints look like relative to our AOI and what is the collection time of the scenes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_scenes = items_to_scenes(landsat_list)\n",
    "\n",
    "# How many Landsat 8 scenes match the query?\n",
    "print(len(landsat_scenes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Landsat 8 Footprints on Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landsat_scenes_to_features_layer(scenes):\n",
    "    features_style = {\n",
    "            'color': 'grey',\n",
    "            'weight': 1,\n",
    "            'fillColor': 'grey',\n",
    "            'fillOpacity': 0.15}\n",
    "\n",
    "    features = [{\"geometry\": r.footprint,\n",
    "                 \"type\": \"Feature\",\n",
    "                 \"properties\": {\"style\": features_style,\n",
    "                                \"wrs_path\": r.wrs_path,\n",
    "                                \"wrs_row\": r.wrs_row}}\n",
    "                for r in scenes.itertuples()]\n",
    "    return features\n",
    "\n",
    "def create_landsat_hover_handler(scenes, label):\n",
    "    def hover_handler(event=None, id=None, properties=None):\n",
    "        wrs_path = properties['wrs_path']\n",
    "        wrs_row = properties['wrs_row']\n",
    "        path_row_query = 'wrs_path=={} and wrs_row=={}'.format(wrs_path, wrs_row)\n",
    "        count = len(scenes.query(path_row_query))\n",
    "        label.value = 'path: {}, row: {}, count: {}'.format(wrs_path, wrs_row, count)\n",
    "    return hover_handler\n",
    "\n",
    "\n",
    "def create_landsat_feature_layer(scenes, label):\n",
    "    \n",
    "    features = landsat_scenes_to_features_layer(scenes)\n",
    "    \n",
    "    # Footprint feature layer\n",
    "    feature_collection = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }\n",
    "\n",
    "    feature_layer = ipyl.GeoJSON(data=feature_collection)\n",
    "\n",
    "    feature_layer.on_hover(create_landsat_hover_handler(scenes, label))\n",
    "    return feature_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize map using parameters from above map\n",
    "# and deleting map instance if it exists\n",
    "try:\n",
    "    del fp_map\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "\n",
    "zoom = 6\n",
    "center = [38.28993659801203, -120.14648437499999] # lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create map, adding box drawing controls\n",
    "# Reuse parameters if map already exists\n",
    "try:\n",
    "    center = fp_map.center\n",
    "    zoom = fp_map.zoom\n",
    "    print(zoom)\n",
    "    print(center)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Change tile layer to one that makes it easier to see crop features\n",
    "# Layer selected using https://leaflet-extras.github.io/leaflet-providers/preview/\n",
    "map_tiles = ipyl.TileLayer(url='http://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}.png')\n",
    "fp_map = ipyl.Map(\n",
    "        center=center, \n",
    "        zoom=zoom,\n",
    "        default_tiles = map_tiles\n",
    "    )\n",
    "\n",
    "label = ipyw.Label(layout=ipyw.Layout(width='100%'))\n",
    "fp_map.add_layer(create_landsat_feature_layer(landsat_scenes, label)) # landsat layer\n",
    "fp_map.add_layer(ipyl.GeoJSON(data=aoi)) # aoi layer\n",
    "    \n",
    "# Display map and label\n",
    "ipyw.VBox([fp_map, label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This AOI is located in a region covered by 3 different path/row tiles. This means there is 3x the coverage than in regions only covered by one path/row tile. This is particularly lucky!\n",
    "\n",
    "What about the within each path/row tile. How long and how consistent is the Landsat 8 collect period for each path/row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_diff_stats(group):\n",
    "    time_diff = group.index.to_series().diff() # time difference between rows in group\n",
    "    stats = {'median': time_diff.median(),\n",
    "             'mean': time_diff.mean(),\n",
    "             'std': time_diff.std(),\n",
    "             'count': time_diff.count(),\n",
    "             'min': time_diff.min(),\n",
    "             'max': time_diff.max()}\n",
    "    return pd.Series(stats)\n",
    "\n",
    "landsat_scenes.groupby(['wrs_path', 'wrs_row']).apply(time_diff_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the collection period is 16 days, which lines up with the [Landsat 8 mission description](https://www.usgs.gov/landsat-missions/landsat-8).\n",
    "\n",
    "path/row 43/33 is missing one image which causes an unusually long collect period.\n",
    "\n",
    "What this means is that we don't need to look at every Landsat 8 scene collect time to find crossovers with Planet scenes. We could look at the first scene for each path/row, then look at every 16 day increment. However, we will need to account for dropped Landsat 8 scenes in some way.\n",
    "\n",
    "What is the time difference between the tiles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "def find_closest(date_time, data_frame):\n",
    "    # inspired by:\n",
    "    # https://stackoverflow.com/questions/36933725/pandas-time-series-join-by-closest-time\n",
    "    \n",
    "    # add timezone to datetime object before subtracting\n",
    "    if date_time.tzinfo is None:\n",
    "        date_time = pytz.utc.localize(date_time)\n",
    "    \n",
    "    \n",
    "    time_deltas = (data_frame.index - date_time).to_series().reset_index(drop=True).abs()\n",
    "    #time_deltas = (data_frame.index - pytz.utc.localize(date_time)).to_series().reset_index(drop=True).abs()\n",
    "    #time_deltas = (data_frame.index.tz_localize(None) - date_time).to_series().reset_index(drop=True).abs()\n",
    "    idx_min = time_deltas.idxmin()\n",
    "\n",
    "    min_delta = time_deltas[idx_min]\n",
    "    return (idx_min, min_delta)\n",
    "\n",
    "def closest_time(group):\n",
    "    '''group: data frame with acquisition time as index'''\n",
    "    inquiry_date = datetime.datetime(year=2017,month=3,day=7)\n",
    "    idx, _ = find_closest(inquiry_date, group)\n",
    "    return group.index.to_series().iloc[idx]\n",
    "\n",
    "\n",
    "# for accurate results, we look at the closest time for each path/row tile to a given time\n",
    "# using just the first entry could result in a longer time gap between collects due to\n",
    "# the timing of the first entries\n",
    "\n",
    "landsat_scenes.groupby(['wrs_path', 'wrs_row']).apply(closest_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the tiles that are in the same path are very close (36sec) together from the same day. Therefore, we would want to only use one tile and pick the best image.\n",
    "\n",
    "Tiles that are in different paths are 7 days apart. Therefore, we want to keep tiles from different paths, as they represent unique crossovers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate PS Orthotiles\n",
    "\n",
    "There are also quite a few PS Orthotiles that match our query. Some of those scenes may not have much overlap with our AOI. We will want to filter those out. Also, we are interested in knowing how many unique days of coverage we have, so we will group PS Orthotiles by collect day, since we may have days with more than one collect (due multiple PS satellites collecting imagery)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ps_scenes = items_to_scenes(psortho_list)\n",
    "\n",
    "# How many PS scenes match query?\n",
    "print(len(all_ps_scenes))\n",
    "all_ps_scenes[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about overlap? We really only want images that overlap over 20% of the AOI.\n",
    "\n",
    "Note: we do this calculation in WGS84, the geographic coordinate system supported by geojson. The calculation of coverage expects that the geometries entered are 2D, which WGS84 is not. This will cause a small inaccuracy in the coverage area calculation, but not enough to bother us here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aoi_overlap_percent(footprint, aoi):\n",
    "    aoi_shape = sgeom.shape(aoi)\n",
    "    footprint_shape = sgeom.shape(footprint)\n",
    "    overlap = aoi_shape.intersection(footprint_shape)\n",
    "    return overlap.area / aoi_shape.area\n",
    "\n",
    "overlap_percent = all_ps_scenes.footprint.apply(aoi_overlap_percent, args=(aoi,))\n",
    "all_ps_scenes = all_ps_scenes.assign(overlap_percent = overlap_percent)\n",
    "all_ps_scenes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_ps_scenes))\n",
    "ps_scenes = all_ps_scenes[all_ps_scenes.overlap_percent > 0.20]\n",
    "print(len(ps_scenes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, PS scenes have daily coverage over all regions. How many days have PS coverage and how many PS scenes were taken on the same day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps_scenes.index.to_series().head()\n",
    "# ps_scenes.filter(items=['id']).groupby(pd.Grouper(freq='D')).agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PS acquisition year, month, and day as index and group by those indices\n",
    "# https://stackoverflow.com/questions/14646336/pandas-grouping-intra-day-timeseries-by-date\n",
    "daily_ps_scenes = ps_scenes.index.to_series().groupby([ps_scenes.index.year,\n",
    "                                                       ps_scenes.index.month,\n",
    "                                                       ps_scenes.index.day])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_count = daily_ps_scenes.agg('count')\n",
    "daily_count.index.names = ['y', 'm', 'd']\n",
    "\n",
    "# How many days is the count greater than 1?\n",
    "daily_multiple_count = daily_count[daily_count > 1]\n",
    "\n",
    "print('Out of {} days of coverage, {} days have multiple collects.'.format( \\\n",
    "    len(daily_count), len(daily_multiple_count)))\n",
    "\n",
    "daily_multiple_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenes_and_count(group):\n",
    "    entry = {'count': len(group),\n",
    "             'acquisition_time': group.index.tolist()}\n",
    "    return pd.DataFrame(entry)\n",
    "\n",
    "daily_count_and_scenes = daily_ps_scenes.apply(scenes_and_count)\n",
    "# need to rename indices because right now multiple are called 'acquired', which\n",
    "# causes a bug when we try to run the query\n",
    "daily_count_and_scenes.index.names = ['y', 'm', 'd', 'num']\n",
    "\n",
    "multiplecoverage = daily_count_and_scenes.query('count > 1')\n",
    "\n",
    "multiplecoverage.query('m == 7')  # look at just occurrence in July"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the multiple collects on the same day are just a few minutes apart. They are likely crossovers between different PS satellites. Cool! Since we only want to us one PS image for a crossover, we will chose the best collect for days with multiple collects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Crossovers\n",
    "\n",
    "Now that we have the PS Orthotiles filtered to what we want and have investigated the Landsat 8 scenes, let's look for crossovers between the two.\n",
    "\n",
    "First we find concurrent crossovers, PS and Landsat collects that occur within 48hours of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_crossovers(acquired_time, landsat_scenes):\n",
    "    '''landsat_scenes: pandas dataframe with acquisition time as index'''\n",
    "    closest_idx, closest_delta = find_closest(acquired_time, landsat_scenes)\n",
    "    closest_landsat = landsat_scenes.iloc[closest_idx]\n",
    "\n",
    "    crossover = {'landsat_acquisition': closest_landsat.name,\n",
    "                 'delta': closest_delta}\n",
    "    return pd.Series(crossover)\n",
    "\n",
    "\n",
    "# fetch PS scenes\n",
    "ps_scenes = items_to_scenes(psortho_list)\n",
    "\n",
    "\n",
    "# for each PS scene, find the closest Landsat scene\n",
    "# Remove timezone info from the datetime index in order to subtract\n",
    "crossovers = ps_scenes.index.to_series().apply(find_crossovers, args=(landsat_scenes,))\n",
    "\n",
    "# filter to crossovers within 28 days\n",
    "concurrent_crossovers = crossovers[crossovers['delta'] < pd.Timedelta('28 days')]\n",
    "print(len(concurrent_crossovers))\n",
    "concurrent_crossovers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the crossovers, what we are really interested in is the IDs of the landsat and PS scenes, as well as how much they overlap the AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crossover_info(crossovers, aoi):\n",
    "    def get_scene_info(acquisition_time, scenes):\n",
    "        scene = scenes.loc[acquisition_time]\n",
    "        scene_info = {'id': scene.id,\n",
    "                      'thumbnail': scene.thumbnail,\n",
    "                      # we are going to use the footprints as shapes so convert to shapes now\n",
    "                      'footprint': sgeom.shape(scene.footprint)}\n",
    "        return pd.Series(scene_info)\n",
    "\n",
    "    landsat_info = crossovers.landsat_acquisition.apply(get_scene_info, args=(landsat_scenes,))\n",
    "    ps_info = crossovers.index.to_series().apply(get_scene_info, args=(ps_scenes,))\n",
    "\n",
    "    footprint_info = pd.DataFrame({'landsat': landsat_info.footprint,\n",
    "                                   'ps': ps_info.footprint})\n",
    "    overlaps = footprint_info.apply(lambda x: x.landsat.intersection(x.ps),\n",
    "                                    axis=1)\n",
    "    \n",
    "    aoi_shape = sgeom.shape(aoi)\n",
    "    overlap_percent = overlaps.apply(lambda x: x.intersection(aoi_shape).area / aoi_shape.area)\n",
    "    crossover_info = pd.DataFrame({'overlap': overlaps,\n",
    "                                   'overlap_percent': overlap_percent,\n",
    "                                   'ps_id': ps_info.id,\n",
    "                                   'ps_thumbnail': ps_info.thumbnail,\n",
    "                                   'landsat_id': landsat_info.id,\n",
    "                                   'landsat_thumbnail': landsat_info.thumbnail})\n",
    "    return crossover_info\n",
    "\n",
    "crossover_info = get_crossover_info(concurrent_crossovers, aoi)\n",
    "print(len(crossover_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we check to see if there are overlaps that cover a significant portion of the AOI. In this case there are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_crossovers_info = crossover_info[crossover_info.overlap_percent > 0.9]\n",
    "print(len(significant_crossovers_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browsing through the crossovers, we see that in some instances, multiple crossovers take place on the same day. Really, we are interested in 'unique crossovers', that is, crossovers that take place on unique days. Therefore, we will look at the concurrent crossovers by day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_day(data_frame):\n",
    "    return data_frame.groupby([data_frame.index.year,\n",
    "                               data_frame.index.month,\n",
    "                               data_frame.index.day])\n",
    "\n",
    "unique_crossover_days = group_by_day(crossover_info.index.to_series()).count()\n",
    "print(len(unique_crossover_days))\n",
    "print(unique_crossover_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 unique crossovers between Landsat 8 and PS that cover over 90% of our AOI between January and August in 2017. Not bad! That is definitely enough to perform comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Crossovers\n",
    "\n",
    "Let's take a quick look at the crossovers we found to make sure that they don't look cloudy, hazy, or have any other quality issues that would affect the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/36006136/how-to-display-images-in-a-row-with-ipython-display\n",
    "def make_html(image):\n",
    "     return '<img src=\"{0}\" alt=\"{0}\"style=\"display:inline;margin:1px\"/>' \\\n",
    "            .format(image)\n",
    "\n",
    "\n",
    "def display_thumbnails(row):\n",
    "    print(row.name)\n",
    "    display(HTML(''.join(make_html(t)\n",
    "                         for t in (row.ps_thumbnail, row.landsat_thumbnail))))\n",
    "\n",
    "_ = crossover_info.apply(display_thumbnails, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "They all look pretty good although the last crossover (2017-08-10) could be a little hazy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
