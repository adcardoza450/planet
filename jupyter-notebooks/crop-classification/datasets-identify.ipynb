{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Datasets\n",
    "\n",
    "This notebook is a part of the [Crop Segmentation and Classification](crop-segmentation-and-classification.ipynb) notebook project. In this notebook, we identify and the ground truth data, define the area of intereste, and identify and download imagery data for use in crop segmentation and classification. We do this for two sets of data: a training set, where we will develop our segmentation and classification algorithms, and a testing set, where we test the accuracy of the resulting segmentation and classification.\n",
    "\n",
    "The general sections are:\n",
    "1. [Explore Ground Truth Data](#ground_truth)\n",
    "2. [Identify Area of Interest](#aoi)\n",
    "3. [Download Planet Scene](#pl_scene)\n",
    "\n",
    "Ground truth crop type and boundary data is not easy to come by. Therefore, the area and time of interest for this problem is primarily defined by the availability of ground truth data. The [2015 Sacramento County Land Use DWR Survey Dataset](http://www.water.ca.gov/landwateruse/lusrvymain.cfm) is a free dataset covering Sacramento county in 2015. It provides hand-adjusted boundaries and provides crop types.\n",
    "\n",
    "The primary satellite imagery we will use in this study is SSO Planetscope 2 imagery. We will use the [Analytic Radiance Ortho Product](https://www.planet.com/products/satellite-imagery/planetscope-analytic-ortho-scene/), which is 4-band (Blue, Green Red, Near-IR) and radiometrically corrected to at-sensor radiance. Correction to at-sensor radiance removes any variation in imagery between different satellites and allows for calculating vegetative indices. Further, the coefficients for correcting to at-sensor reflectance are provided in the scene metadata, which further improves the consistency between images taken at different times.\n",
    "\n",
    "SSO Planetscope 2 satellites were launched Feb 14, 2017 ([news release](https://www.planet.com/pulse/planet-launches-satellite-constellation-to-image-the-whole-planet-daily/)), therefore they did not image Sacramento county in 2015. Although at this time we are focusing on PlanetScope imagery, in the future we may use Landsat 8 imagery as a bridge between 2015 and 2017.\n",
    "\n",
    "### Usage Notes\n",
    "\n",
    "This notebook was developed in a Docker container. This [Dockerfile](Dockerfile) was used to build the image.\n",
    "\n",
    "The user-specific planet api key must be stored in the environmental variable $PL_API_KEY. To pass this key into the Docker container, add -e PL_API_KEY=your_api_key when you call docker run (replace 'your_api_key' with your api key).\n",
    "\n",
    "Python dependencies are tracked in the conda environmental files `root.yml` (for Python3 dependencies) and `python2.yml` (for Python2 dependencies and the conda environment that is used in this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notebook dependencies\n",
    "from __future__ import print_function\n",
    "\n",
    "import copy\n",
    "import datetime\n",
    "from functools import partial\n",
    "import json\n",
    "import os\n",
    "\n",
    "import ipyleaflet as ipyl\n",
    "import ipywidgets as ipyw\n",
    "from IPython.display import display, Image\n",
    "import fiona\n",
    "import pandas as pd\n",
    "from planet import api\n",
    "from planet.api import filters\n",
    "import pyproj\n",
    "import shapely\n",
    "from shapely.geometry import shape, mapping\n",
    "from shapely.ops import transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ground_truth'></a>\n",
    "\n",
    "## Explore Ground Truth Data\n",
    "\n",
    "In this section we will download the ground truth data, filter it to crop features, and save it as a geojson dataset (geojson is our preferred format for processing in these notebooks).\n",
    "\n",
    "\n",
    "#### Download data\n",
    "To obtain and prepare the ground truth data, we first download the shapefile zip file from (http://www.water.ca.gov/landwateruse/docs/landusedata/shapes/15sa.zip) and then unzip into /data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment lines to download and unzip data\n",
    "# !mkdir data\n",
    "# !mkdir data/dwr_survey\n",
    "# !wget http://www.water.ca.gov/landwateruse/docs/landusedata/shapes/15sa.zip\n",
    "# !unzip 15sa.zip -d data/dwr_survey/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify the shapefile location and ensure it indeed exists\n",
    "survey_shapefile = 'data/dwr_survey/SA15.shp'\n",
    "assert os.path.isfile(survey_shapefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data\n",
    "\n",
    "The data is provided as a shapefile. It is easier to process the data as geojson. Therefore, we will convert the data to geojson. Additionally, the data contains polygons that aren't crops. Since we are only interested in crops, we will filter the data to only the crop polygons.\n",
    "\n",
    "We will use [fiona](http://toblerity.org/fiona/manual.html) to load the shapefile, [shapely](http://toblerity.org/shapely/manual.html) to manage the geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reproject to WGS84\n",
    "\n",
    "What is the coordinate reference system for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsg:26910\n"
     ]
    }
   ],
   "source": [
    "src_proj = fiona.open(survey_shapefile, 'r').crs['init']\n",
    "print(src_proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out it is [EPSG:26910](http://spatialreference.org/ref/epsg/26910/). Geojson only supports [EPSG:4326](http://spatialreference.org/ref/epsg/4326/). We will need to reproject the shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define projection\n",
    "# from shapely [docs](http://toblerity.org/shapely/manual.html#shapely.ops.transform)\n",
    "def define_to_wkt_projection(dataset):\n",
    "    \"\"\"dataset is obtained from fiona.open(file)\"\"\"\n",
    "    src_proj = dataset.crs['init']\n",
    "    dst_proj = 'epsg:4326'\n",
    "\n",
    "    project_to_wkt = partial(\n",
    "        pyproj.transform,\n",
    "        pyproj.Proj(init=src_proj),\n",
    "        pyproj.Proj(init=dst_proj))\n",
    "    return project_to_wkt\n",
    "\n",
    "def project_feature(feat, projection_fcn):\n",
    "    g1 = shape(feat['geometry'])\n",
    "    g2 = transform(projection_fcn, g1)\n",
    "    feat['geometry'] = mapping(g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter to agricultural classes\n",
    "\n",
    "The survey data has attributes that provide the crop type. These attributes are described in a pdf distributed with the shapefile. It was unzipped along with the shapefile files and is located at `data/dwr_survey/09legend.pdf`.\n",
    "\n",
    "We are interested in the agricultural classes. Class is specified by the 'CLASS1' attribute of the feature.\n",
    "\n",
    "The agricultural class label and descriptions are:\n",
    "- G: Grain and Hay Crops\n",
    "- R: Rice\n",
    "- F: Field Crops\n",
    "- P: Pasture\n",
    "- T: Truck, Nursery, and Berry Crops\n",
    "- D: Deciduous Fruits and Nutes\n",
    "- C: Citrus and Tropical\n",
    "- V: Vineyards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class ids from dwr_survey/09legend.pdf\n",
    "agg_classes = ['G', 'R', 'F', 'P', 'T', 'D', 'C', 'V']\n",
    "\n",
    "def is_agricultural(feat):\n",
    "    return feat['properties']['CLASS1'] in agg_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally: Load data\n",
    "\n",
    "Load the ground truth data into a list of geojson features, filtering to only agricultural classes and projecting to wkt. Because this process takes a while, save the loaded features for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7429\n"
     ]
    }
   ],
   "source": [
    "def load_ground_truth(filename):\n",
    "    features = []\n",
    "    with fiona.open(filename) as survey_data:\n",
    "        to_wkt_projection = define_to_wkt_projection(survey_data)\n",
    "        for feat in survey_data:\n",
    "            if is_agricultural(feat):\n",
    "                project_feature(feat, to_wkt_projection)\n",
    "                features.append(feat)\n",
    "    return features\n",
    "\n",
    "features = load_ground_truth(survey_shapefile)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aoi'></a>\n",
    "\n",
    "## Identify Area of Interest\n",
    "\n",
    "In this section we will identify an area of interest (aoi) for each study. \n",
    "\n",
    "Selection of the area of interest for our study is based on the following:\n",
    "1. compact representation of many crop classes\n",
    "2. availability of imagery\n",
    "3. as large as possible but smaller than a planet image (to allow for in-scene analysis)\n",
    "\n",
    "We visualize the ground truth data in an interactive window that allows definition of the aoi. Then we query the Planet API to determine the availability of imatery. After using this interactive visualization, we identified two AOIs, which are defined in the notebook as `aoi_test` and `aoi_train`. Next, we identify the Planet scene we want to download for our study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criteria 1: compact representation of many crop classes\n",
    "\n",
    "Let's start by identifying a region of compact representation of many crop classes. We will do so by drawing a box (the aoi) over the map of the crops and then displaying the number of unique classes represented in the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign colors to classes\n",
    "# colors determined using [colorbrewer2.org](http://colorbrewer2.org/#type=sequential&scheme=BuGn&n=3)\n",
    "colors = ['#ffffd9','#edf8b1','#c7e9b4','#7fcdbb','#41b6c4','#1d91c0','#225ea8','#0c2c84']\n",
    "class_colors = dict((a,c) for a,c in zip(agg_classes, colors))\n",
    "\n",
    "def get_color(cls):\n",
    "    return class_colors[cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create crop feature layer\n",
    "feature_collection = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "for f in feature_collection['features']:\n",
    "    feature_color = get_color(f['properties']['CLASS1'])\n",
    "    f['properties']['style'] = {\n",
    "        'weight': 0,\n",
    "        'fillColor': feature_color,\n",
    "        'fillOpacity': 1}\n",
    "\n",
    "feature_layer = ipyl.GeoJSON(data=feature_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize map using parameters from above map\n",
    "# and deleting map instance if it exists\n",
    "try:\n",
    "    del aoi_map\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "\n",
    "zoom = 11\n",
    "center = [38.3586252, -121.3853994] # lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2a6d8ebde5451381c227674062b959"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create map, adding box drawing controls\n",
    "# Reuse parameters if map already exists\n",
    "try:\n",
    "    center = aoi_map.center\n",
    "    zoom = aoi_map.zoom\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Change tile layer to one that makes it easier to see crop features\n",
    "# Layer selected using https://leaflet-extras.github.io/leaflet-providers/preview/\n",
    "map_tiles = ipyl.TileLayer(url='http://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}.png')\n",
    "aoi_map = ipyl.Map(\n",
    "        center=center, \n",
    "        zoom=zoom,\n",
    "        default_tiles = map_tiles\n",
    "    )\n",
    "\n",
    "aoi_map.add_layer(feature_layer)  \n",
    "\n",
    "# Add box drawing control\n",
    "# refs:\n",
    "# https://github.com/kscottz/PythonFromSpace/blob/master/TheBasics.ipynb\n",
    "# https://github.com/ellisonbg/ipyleaflet/blob/master/examples/DrawControl.ipynb\n",
    "rectangle = {'shapeOptions': {'color': 'blue'}} \n",
    "dc = ipyl.DrawControl(\n",
    "    polygon={}, polyline={}, # disable polygons and polylines\n",
    "    rectangle={'shapeOptions': {'color': 'blue'}}\n",
    ")\n",
    "\n",
    "# When a box is drawn, update the label with the number of unique classes\n",
    "# and save the box geometry as AOI\n",
    "total_unique_classes = len(set([f['properties']['CLASS1'] for f in features]))\n",
    "label = ipyw.Label(layout=ipyw.Layout(width='100%'))\n",
    "\n",
    "aois = []\n",
    "def handle_draw(self, action, geo_json):\n",
    "    if action == 'created':\n",
    "        box_shape = shape(geo_json['geometry'])\n",
    "        contained_features = [f for f in features\n",
    "                              if shape(f['geometry']).within(box_shape)]\n",
    "        unique_classes = set([f['properties']['CLASS1'] for f in contained_features])\n",
    "        label.value = '{} unique classes out of {} total'.format(\n",
    "            len(unique_classes), total_unique_classes)\n",
    "        aois.append(geo_json)\n",
    "    elif action == 'deleted':\n",
    "        aois.remove(geo_json)\n",
    "    \n",
    "dc.on_draw(handle_draw)\n",
    "aoi_map.add_control(dc) \n",
    "\n",
    "# Display map and label\n",
    "ipyw.VBox([aoi_map, label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this map, we have identified two potential aois for a training dataset and a testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this to use cached aois\n",
    "aoi_train = {u'geometry': {u'type': u'Polygon', u'coordinates': [[[-121.58460974693298, 38.29170496647727], [-121.58460974693298, 38.32726528409606], [-121.5248715877533, 38.32726528409606], [-121.5248715877533, 38.29170496647727], [-121.58460974693298, 38.29170496647727]]]}, u'type': u'Feature', u'properties': {u'style': {u'opacity': 0.5, u'noClip': False, u'weight': 4, u'fillColor': None, u'color': u'blue', u'lineCap': None, u'stroke': True, u'smoothFactor': 1, u'dashArray': None, u'fillOpacity': 0.2, u'clickable': True, u'lineJoin': None, u'fill': True}}}\n",
    "aoi_test = {u'geometry': {u'type': u'Polygon', u'coordinates': [[[-121.3113248348236, 38.28911976564886], [-121.3113248348236, 38.34622533958], [-121.2344205379486, 38.34622533958], [-121.2344205379486, 38.28911976564886], [-121.3113248348236, 38.28911976564886]]]}, u'type': u'Feature', u'properties': {u'style': {u'opacity': 0.5, u'fillOpacity': 0.2, u'noClip': False, u'weight': 4, u'color': u'blue', u'lineCap': None, u'dashArray': None, u'smoothFactor': 1, u'stroke': True, u'fillColor': None, u'clickable': True, u'lineJoin': None, u'fill': True}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criteria 2: availability of imagery\n",
    "\n",
    "How many PL images cover the AOI defined above?\n",
    "\n",
    "We will answer this question by querying the planet api. The client is how we interact with the planet api. It is created with the user-specific api key, which is pulled from $PL_API_KEY\n",
    "\n",
    "[planet client documentation](https://planetlabs.github.io/planet-client-python/index.html) \n",
    "\n",
    "Much of this code is pulled from [PythonFromSpace/TheBasics.ipynb](https://github.com/kscottz/PythonFromSpace/blob/master/TheBasics.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_api_key():\n",
    "    return os.environ['PL_API_KEY']\n",
    "\n",
    "# quick check that key is defined\n",
    "assert get_api_key(), \"PL_API_KEY not defined.\"\n",
    "\n",
    "def create_client():\n",
    "    return api.ClientV1(api_key=get_api_key())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Planet API\n",
    "\n",
    "Filter to scenes that contain AOI. If the number is zero, go back and redefine the AOI to be smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def search_by_aoi(aoi):\n",
    "#     old = datetime.datetime(year=2016,month=6,day=1)\n",
    "#     new = datetime.datetime(year=2016,month=10,day=1)\n",
    "\n",
    "#     search_aoi = aoi['geometry']\n",
    "#     query = filters.and_filter(\n",
    "#         filters.geom_filter(search_aoi),\n",
    "# #         filters.range_filter('cloud_cover', lt=0.00000000000005),\n",
    "#         filters.date_range('acquired', gt=old),\n",
    "#         filters.date_range('acquired', lt=new)\n",
    "#     )\n",
    "\n",
    "#     # build a request for Planetscope and Sentinel imagery\n",
    "#     request = filters.build_search_request(\n",
    "#         query, item_types=['PSOrthoTile']\n",
    "#     )\n",
    "\n",
    "#     # run search\n",
    "#     # if you don't have an API key configured, this will raise an exception\n",
    "#     results = client.quick_search(request)\n",
    "#     return results\n",
    "# results_test = search_by_aoi(aoi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thumb = results[0]['_links']['thumbnail']\n",
    "# print(thumb)\n",
    "# display(Image(url=thumb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def build_request(aoi, item_types):\n",
    "    old = datetime.datetime(year=2016,month=6,day=1)\n",
    "    new = datetime.datetime(year=2016,month=10,day=1)\n",
    "\n",
    "    search_aoi = aoi['geometry']\n",
    "    query = filters.and_filter(\n",
    "        filters.geom_filter(search_aoi),\n",
    "        filters.range_filter('cloud_cover', lt=5),\n",
    "        filters.date_range('acquired', gt=old),\n",
    "        filters.date_range('acquired', lt=new)\n",
    "    )\n",
    "\n",
    "    return filters.build_search_request(query, item_types)\n",
    "\n",
    "\n",
    "def search_pl_api(request, limit=500):\n",
    "    client = create_client()\n",
    "    result = client.quick_search(request)\n",
    "    return result.items_iter(limit=limit)\n",
    "\n",
    "\n",
    "def items_to_scenes(items, aoi):\n",
    "    aoi_shape = geometry.shape(aoi['geometry'])\n",
    "    \n",
    "    def _calculate_overlap(footprint_shape):\n",
    "        return mapping(aoi_shape.intersection(footprint_shape))\n",
    "\n",
    "    def _overlap_percent(footprint_shape):\n",
    "        return 100.0 * (aoi_shape.intersection(footprint_shape).area / aoi_shape.area)\n",
    "    \n",
    "    def _get_props(item):\n",
    "        props = item['properties']\n",
    "        props['id'] = item['id']\n",
    "        props['footprint'] = item['geometry']\n",
    "        props['thumbnail'] = item['_links']['thumbnail']\n",
    "        \n",
    "        footprint_shape = geometry.shape(props['footprint'])\n",
    "        props['overlap'] = _calculate_overlap(footprint_shape)\n",
    "        props['coverage'] = _overlap_percent(footprint_shape)\n",
    "        return props\n",
    "    scenes = pd.DataFrame(data=[_get_props(i) for i in items])\n",
    "    \n",
    "    scenes['acquired'] = pd.to_datetime(scenes['acquired'])\n",
    "    scenes['published'] = pd.to_datetime(scenes['published'])\n",
    "    scenes['updated'] = pd.to_datetime(scenes['updated'])\n",
    "    return scenes\n",
    "\n",
    "\n",
    "def get_full_coverage_scenes(aoi):\n",
    "    request = build_request(aoi, ['PSScene4Band'])\n",
    "    items = search_pl_api(request)\n",
    "    scenes = items_to_scenes(items, aoi)\n",
    "\n",
    "    full_coverage = scenes['coverage'] > 99\n",
    "    return scenes[(full_coverage)]\n",
    "\n",
    "scenes_test = get_full_coverage_scenes(aoi_test)\n",
    "print(len(scenes_test))\n",
    "\n",
    "scenes_train = get_full_coverage_scenes(aoi_train)\n",
    "print(len(scenes_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comparison_scenes(aoi, item_types):\n",
    "    request = build_request(aoi, item_types)\n",
    "    items = search_pl_api(request)\n",
    "    return items_to_scenes(items, aoi)\n",
    "\n",
    "ps_orthotile = get_comparison_scenes(aoi_test, ['PSOrthoTile'])\n",
    "l8_scene = get_comparison_scenes(aoi_test, ['Landsat8L1G'])\n",
    "s2_orthotile = get_comparison_scenes(aoi_test, ['Sentinel2L1C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 3.00, 0.00, 631389.00|\n",
      "| 0.00,-3.00, 4250643.00|\n",
      "| 0.00, 0.00, 1.00|\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "print(rasterio.open('data/test/20160831_180257_0e26_3B_AnalyticMS.tif').transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRS({'init': u'epsg:32610'})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasterio.open('data/test/20160831_180257_0e26_3B_AnalyticMS.tif').crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ps_orthotile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5ce2c37b6e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfootprints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps_orthotile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overlap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# footprints = l8_scene['overlap'].tolist()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ps_orthotile' is not defined"
     ]
    }
   ],
   "source": [
    "from rasterio import features\n",
    "from shapely import geometry\n",
    "import numpy as np\n",
    "\n",
    "footprints = ps_orthotile['overlap'].tolist()\n",
    "\n",
    "# footprints = l8_scene['overlap'].tolist()\n",
    "x_count = y_count = 10\n",
    "shape = (y_count, x_count)\n",
    "coverage = np.zeros(shape, dtype=np.uint8)\n",
    "\n",
    "for fp in footprints:\n",
    "    print(fp)\n",
    "    minx, miny, maxx, maxy = geometry.shape(fp).bounds\n",
    "    width = (maxx - minx) / x_count\n",
    "    height = (miny - maxy) / y_count\n",
    "    print(rasterio.Affine(width,0,minx,0,height,maxy))\n",
    "    display(geometry.shape(fp))\n",
    "    image = features.rasterize(\n",
    "            (fp),\n",
    "            out_shape=shape,\n",
    "            transform=rasterio.Affine(width,0,minx,0,height,maxy))\n",
    "    print(image)\n",
    "\n",
    "display(coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize subset of scene thumbnails and then select one\n",
    "\n",
    "If all you see are broken image icons, click one of the urls and log into the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_thumbnails(scenes, limit=10):\n",
    "    for thumb_url in scenes['thumbnail'].tolist()[:limit]:\n",
    "        img_image = Image(url=thumb_url)\n",
    "        display(img_image)\n",
    "        print(thumb_url)\n",
    "\n",
    "# Uncomment one of the lines below to display the thumbnails\n",
    "# display_thumbnails(scenes_train, limit=5)\n",
    "# display_thumbnails(scenes_test, limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the train scenes, https://api.planet.com/data/v1/item-types/PSScene4Band/items/20160831_180231_0e0e/thumb looks pretty good. It is from August 2016 and looks clear of clouds.\n",
    "\n",
    "For the test scenes, https://api.planet.com/data/v1/item-types/PSScene4Band/items/20160831_180257_0e26/thumb looks great. It is from the same day as the train scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_thumbnail = 'https://api.planet.com/data/v1/item-types/PSScene4Band/items/20160831_180231_0e0e/thumb'\n",
    "display(Image(url=train_thumbnail))\n",
    "\n",
    "test_thumbnail = 'https://api.planet.com/data/v1/item-types/PSScene4Band/items/20160831_180257_0e26/thumb'\n",
    "display(Image(url=test_thumbnail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pl_scene'></a>\n",
    "\n",
    "## Save datasets\n",
    "\n",
    "For each dataset, we will save the AOIs, ground truth data, and scenes. We have defined two datasets: test and train.\n",
    "\n",
    "We will download the train and test scenes and along with their metadata using the planet client cli. This approach requires much less code than using the python bindings.\n",
    "\n",
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir data/train\n",
    "!planet data download --item-type PSScene4Band --dest data/train \\\n",
    "    --asset-type analytic,analytic_xml --string-in id 20160831_180231_0e0e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_geojson(features, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(json.dumps(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join('data', 'train')\n",
    "\n",
    "# save AOI\n",
    "save_geojson(aoi_train, os.path.join(data_dir, 'aoi.geojson'))\n",
    "\n",
    "# save ground truth data\n",
    "save_geojson(features, os.path.join(data_dir, 'ground-truth.geojson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data/test’: File exists\n",
      "\u001b[2J\u001b[1;1H\u001b[2J\u001b[1;1H\u001b[30;47mactivating: 0            complete: 0              elapsed: 0                    \n",
      "paging: False            pending: 0                                             \u001b[39;49m\n",
      "\n",
      "\u001b[2J\u001b[1;1H\u001b[30;47mactivating: 1            complete: 0              downloaded: 0.00MB            \n",
      "downloading: 0           elapsed: 1               paging: False                 \n",
      "pending: 0                                                                      \u001b[39;49m\n",
      "\n",
      "\u001b[2J\u001b[1;1H\u001b[30;47mactivating: 0            complete: 0              downloaded: 0.00MB            \n",
      "downloading: 1           elapsed: 2               paging: False                 \n",
      "pending: 1                                                                      \u001b[39;49m\n",
      "\n",
      "\u001b[2J\u001b[1;1H\u001b[30;47mactivating: 0            complete: 0              downloaded: 0.00MB            \n",
      "downloading: 2           elapsed: 3               paging: False                 \n",
      "pending: 0                                                                      \u001b[39;49m\n",
      "\n",
      "\u001b[2J\u001b[1;1H\u001b[30;47mactivating: 0            complete: 1              downloaded: 0.00MB            \n",
      "downloading: 1           elapsed: 4               paging: False                 \n",
      "pending: 0                                                                      \u001b[39;49m\n",
      "\n",
      "\u001b[2J\u001b[1;1H\u001b[30;47mactivating: 0            complete: 0              downloaded: 0.00MB            \n",
      "downloading: 1           elapsed: 5               paging: False                 \n",
      "pending: 0                                                                      \u001b[39;49m\n",
      "\n",
      "\u001b[2J\u001b[1;1H\u001b[30;47mactivating: 0            complete: 0              downloaded: 0.00MB            \n",
      "downloading: 1           elapsed: 5               paging: False                 \n",
      "pending: 0                                                                      \u001b[39;49m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data/test\n",
    "!planet data download --item-type PSScene4Band --dest data/test \\\n",
    "    --asset-type analytic,analytic_xml --string-in id 20160831_180257_0e26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join('data', 'test')\n",
    "\n",
    "# save AOI\n",
    "save_geojson(aoi_test, os.path.join(data_dir, 'aoi.geojson'))\n",
    "\n",
    "# save ground truth data\n",
    "save_geojson(features, os.path.join(data_dir, 'ground-truth.geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
